

# 尺寸缩放+fast+2层沙漏网络递归+40000迭代步长
sc-inv, a10, a1, a2, a3, rmse, log_rmse, rel, sq_rel1, sq_rel2, log10, 
0.0900,0.9811,     0.9844,     0.9882,     0.9898,     0.1158,     0.0903,     0.0214,     0.0152,     0.0238,     0.0070,
0.2981,0.5762,     0.7173,     0.7851,     0.8636,     0.5124,     0.3344,     0.2761,     0.2434,     0.2468,     0.0899,

单帧处理时间 0.025656700134277344 ms


[stage=2, 38800] loss: 0.024921896
[stage=2, 38900] loss: 0.024963490
[stage=2, 39000] loss: 0.024508086
[stage=2, 39100] loss: 0.024538921
[stage=2, 39200] loss: 0.025280902
[stage=2, 39300] loss: 0.024285481
[stage=2, 39400] loss: 0.024403310
[stage=2, 39500] loss: 0.025344418
[stage=2, 39600] loss: 0.024137927
[stage=2, 39700] loss: 0.025372589
[stage=2, 39800] loss: 0.024264841
[stage=2, 39900] loss: 0.024786476



# molible 
loss 0.035

sc-inv, a10, a1, a2, a3, rmse, log_rmse, rel, sq_rel1, sq_rel2, log10, 
0.2981,0.5762,0.7173,0.7851,0.8636,0.5124,0.3344,     0.2761,     0.2434,     0.2468,     0.0899,

处理时长:
0.38


2021-02-08 18:22:24.154980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
[stage=2,   100] loss: 0.870698324
[stage=2,   200] loss: 0.278681766
[stage=2,   300] loss: 0.212328424
[stage=2,   400] loss: 0.193610742
[stage=2,   500] loss: 0.163854433
[stage=2,   600] loss: 0.167484757
[stage=2,   700] loss: 0.150005543
[stage=2,   800] loss: 0.142340063
[stage=2,   900] loss: 0.127273803
[stage=2,  1000] loss: 0.128090183
[stage=2,  1100] loss: 0.120468385
[stage=2,  1200] loss: 0.115119815
[stage=2,  1300] loss: 0.106226591
[stage=2,  1400] loss: 0.109299256
[stage=2,  1500] loss: 0.099062484
[stage=2,  1600] loss: 0.099547900
[stage=2,  1700] loss: 0.098269491
[stage=2,  1800] loss: 0.093012106
[stage=2,  1900] loss: 0.088795761
[stage=2,  2000] loss: 0.089235692
[stage=2,  2100] loss: 0.083081102
[stage=2,  2200] loss: 0.085830178
[stage=2,  2300] loss: 0.085439604
[stage=2,  2400] loss: 0.082909350
[stage=2,  2500] loss: 0.080252112
[stage=2,  2600] loss: 0.080991268
[stage=2,  2700] loss: 0.078824043
[stage=2,  2800] loss: 0.081253806
[stage=2,  2900] loss: 0.076483033
[stage=2,  3000] loss: 0.078624670
[stage=2,  3100] loss: 0.075250710
[stage=2,  3200] loss: 0.071488448
[stage=2,  3300] loss: 0.074093273
[stage=2,  3400] loss: 0.072364145
[stage=2,  3500] loss: 0.068015362
[stage=2,  3600] loss: 0.072173180
[stage=2,  3700] loss: 0.072305708
[stage=2,  3800] loss: 0.071512729
[stage=2,  3900] loss: 0.071858313
[stage=2,  4000] loss: 0.070490836
[stage=2,  4100] loss: 0.066975040
[stage=2,  4200] loss: 0.065389452
[stage=2,  4300] loss: 0.066101597
[stage=2,  4400] loss: 0.066165975
[stage=2,  4500] loss: 0.065645462
[stage=2,  4600] loss: 0.067076836
[stage=2,  4700] loss: 0.064765492
[stage=2,  4800] loss: 0.066341343
[stage=2,  4900] loss: 0.062238229
[stage=2,  5000] loss: 0.062112286
[stage=2,  5100] loss: 0.060315233
[stage=2,  5200] loss: 0.060608946
[stage=2,  5300] loss: 0.059664551
[stage=2,  5400] loss: 0.059532973
[stage=2,  5500] loss: 0.059261202
[stage=2,  5600] loss: 0.058403442
[stage=2,  5700] loss: 0.058585812
[stage=2,  5800] loss: 0.058415973
[stage=2,  5900] loss: 0.059151587
[stage=2,  6000] loss: 0.054835729
[stage=2,  6100] loss: 0.057548985
[stage=2,  6200] loss: 0.055854734
[stage=2,  6300] loss: 0.058637120
[stage=2,  6400] loss: 0.055308391
[stage=2,  6500] loss: 0.054878416
[stage=2,  6600] loss: 0.056272317
[stage=2,  6700] loss: 0.053666884
[stage=2,  6800] loss: 0.054419951
[stage=2,  6900] loss: 0.054111161
[stage=2,  7000] loss: 0.054326945
[stage=2,  7100] loss: 0.055096244
[stage=2,  7200] loss: 0.052485253
[stage=2,  7300] loss: 0.053976654
[stage=2,  7400] loss: 0.052227510
[stage=2,  7500] loss: 0.052800995
[stage=2,  7600] loss: 0.052305346
[stage=2,  7700] loss: 0.056278117
[stage=2,  7800] loss: 0.052007127
[stage=2,  7900] loss: 0.050405769
[stage=2,  8000] loss: 0.050630975
[stage=2,  8100] loss: 0.050513648
[stage=2,  8200] loss: 0.051535786
[stage=2,  8300] loss: 0.048308256
[stage=2,  8400] loss: 0.049967059
[stage=2,  8500] loss: 0.049569668
[stage=2,  8600] loss: 0.048572640
[stage=2,  8700] loss: 0.048574965
[stage=2,  8800] loss: 0.048808440
[stage=2,  8900] loss: 0.049340335
[stage=2,  9000] loss: 0.047347868
[stage=2,  9100] loss: 0.049065913
[stage=2,  9200] loss: 0.048557230
[stage=2,  9300] loss: 0.050197474
[stage=2,  9400] loss: 0.047159738
[stage=2,  9500] loss: 0.046828502
[stage=2,  9600] loss: 0.046476180
[stage=2,  9700] loss: 0.046233777
[stage=2,  9800] loss: 0.047489238
[stage=2,  9900] loss: 0.045150478
[stage=2, 10000] loss: 0.046128653
[stage=2, 10100] loss: 0.046784003
[stage=2, 10200] loss: 0.046199276
[stage=2, 10300] loss: 0.045688411
[stage=2, 10400] loss: 0.044008162
[stage=2, 10500] loss: 0.044728714
[stage=2, 10600] loss: 0.044460862
[stage=2, 10700] loss: 0.044621787
[stage=2, 10800] loss: 0.043874301
[stage=2, 10900] loss: 0.044317359
[stage=2, 11000] loss: 0.042811608
[stage=2, 11100] loss: 0.043360097
[stage=2, 11200] loss: 0.044458049
[stage=2, 11300] loss: 0.044405660
[stage=2, 11400] loss: 0.043720082
[stage=2, 11500] loss: 0.042452420
[stage=2, 11600] loss: 0.044476247
[stage=2, 11700] loss: 0.041503030
[stage=2, 11800] loss: 0.043742055
[stage=2, 11900] loss: 0.042436744
[stage=2, 12000] loss: 0.043228767
[stage=2, 12100] loss: 0.044000533
[stage=2, 12200] loss: 0.044881403
[stage=2, 12300] loss: 0.041324706
[stage=2, 12400] loss: 0.042489324
[stage=2, 12500] loss: 0.041506157
[stage=2, 12600] loss: 0.043136746
[stage=2, 12700] loss: 0.039721011
[stage=2, 12800] loss: 0.041400372
[stage=2, 12900] loss: 0.041166099
[stage=2, 13000] loss: 0.041620388
[stage=2, 13100] loss: 0.040246734
[stage=2, 13200] loss: 0.042075597
[stage=2, 13300] loss: 0.040372963
[stage=2, 13400] loss: 0.040769301
[stage=2, 13500] loss: 0.041686249
[stage=2, 13600] loss: 0.040782904
[stage=2, 13700] loss: 0.039500226
[stage=2, 13800] loss: 0.041148624
[stage=2, 13900] loss: 0.042256935
[stage=2, 14000] loss: 0.040138263
[stage=2, 14100] loss: 0.040584024
[stage=2, 14200] loss: 0.039493700
[stage=2, 14300] loss: 0.040129710
[stage=2, 14400] loss: 0.038381801
[stage=2, 14500] loss: 0.039675385
[stage=2, 14600] loss: 0.040230723
[stage=2, 14700] loss: 0.039680481
[stage=2, 14800] loss: 0.037828255
[stage=2, 14900] loss: 0.039346111
[stage=2, 15000] loss: 0.040648800
[stage=2, 15100] loss: 0.037689345
[stage=2, 15200] loss: 0.039108106
[stage=2, 15300] loss: 0.038146662
[stage=2, 15400] loss: 0.040840785
[stage=2, 15500] loss: 0.038368091
[stage=2, 15600] loss: 0.039931861
[stage=2, 15700] loss: 0.038325385
[stage=2, 15800] loss: 0.037546003
[stage=2, 15900] loss: 0.038410622
[stage=2, 16000] loss: 0.038003400
[stage=2, 16100] loss: 0.034748153
[stage=2, 16200] loss: 0.032701684
[stage=2, 16300] loss: 0.032332459
[stage=2, 16400] loss: 0.032413417
[stage=2, 16500] loss: 0.031760196
[stage=2, 16600] loss: 0.032528771
[stage=2, 16700] loss: 0.031577191
[stage=2, 16800] loss: 0.030854716
[stage=2, 16900] loss: 0.031123693
[stage=2, 17000] loss: 0.031399984
[stage=2, 17100] loss: 0.032399717
[stage=2, 17200] loss: 0.030827055
[stage=2, 17300] loss: 0.031536155
[stage=2, 17400] loss: 0.030859927
[stage=2, 17500] loss: 0.031278259
[stage=2, 17600] loss: 0.031255778
[stage=2, 17700] loss: 0.031342752
[stage=2, 17800] loss: 0.030481302
[stage=2, 17900] loss: 0.031204959
[stage=2, 18000] loss: 0.030781539
[stage=2, 18100] loss: 0.030686454
[stage=2, 18200] loss: 0.032199450
[stage=2, 18300] loss: 0.029796402
[stage=2, 18400] loss: 0.030477698
[stage=2, 18500] loss: 0.030770397
[stage=2, 18600] loss: 0.030683142
[stage=2, 18700] loss: 0.030714469
[stage=2, 18800] loss: 0.030674805
[stage=2, 18900] loss: 0.030328643
[stage=2, 19000] loss: 0.030922395
[stage=2, 19100] loss: 0.030075908
[stage=2, 19200] loss: 0.030677921
[stage=2, 19300] loss: 0.030375732
[stage=2, 19400] loss: 0.030490543
[stage=2, 19500] loss: 0.031058110
[stage=2, 19600] loss: 0.031220328
[stage=2, 19700] loss: 0.029262417
[stage=2, 19800] loss: 0.030942549
[stage=2, 19900] loss: 0.030269140

time cost 0.040457963943481445 ms
sc-inv, a10, a1, a2, a3, rmse, log_rmse, rel, sq_rel1, sq_rel2, log10, 
0.3070,     0.6230,     0.6944,     0.7595,     0.8424,     0.5431,     0.3534,     0.2948,     0.2767,     0.2819,     0.0934,